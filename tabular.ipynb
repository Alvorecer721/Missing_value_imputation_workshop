{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### IMPUTATION ###\n",
    "\n",
    "# MissForest imputation\n",
    "from missforest import MissForest\n",
    "\n",
    "# GAIN imputation\n",
    "from hyperimpute.plugins.imputers import Imputers\n",
    "\n",
    "# Generic time series imputation\n",
    "import pypots\n",
    "from pypots.optim import Adam\n",
    "from pypots.imputation import CSDI\n",
    "from pypots.utils.random import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Users/yixuan/workshop'\n",
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/sdg-yixuan-cpu-advanced/code/Users/yixuan/workshop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/workshop/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd Users/yixuan/workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    cal_ml_efficiency,\n",
    "    cal_metrics,\n",
    "    gene_missing_at_random,\n",
    "    impute_missing_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed-type Tabular + Missing Not at Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNAR data\n",
    "cirrhosis = pd.read_csv(\"data/cirrhosis.csv\")\n",
    "categorical_columns = [\n",
    "    \"Status\",\n",
    "    \"Drug\",\n",
    "    \"Sex\",\n",
    "    \"Ascites\",\n",
    "    \"Hepatomegaly\",\n",
    "    \"Spiders\",\n",
    "    \"Edema\",\n",
    "    \"Stage\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a first glance of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 0\n",
       "N_Days             0\n",
       "Status             0\n",
       "Drug             106\n",
       "Age                0\n",
       "Sex                0\n",
       "Ascites          106\n",
       "Hepatomegaly     106\n",
       "Spiders          106\n",
       "Edema              0\n",
       "Bilirubin          0\n",
       "Cholesterol      134\n",
       "Albumin            0\n",
       "Copper           108\n",
       "Alk_Phos         106\n",
       "SGOT             106\n",
       "Tryglicerides    136\n",
       "Platelets         11\n",
       "Prothrombin        2\n",
       "Stage              6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cirrhosis.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to check if the data has the issue of class imbalance to decide which evaluation metric is more appropriate for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status\n",
       "C     232\n",
       "D     161\n",
       "CL     25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cirrhosis.Status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also let's check the class imbalance for rows with any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status\n",
       "C     85\n",
       "D     50\n",
       "CL     7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cirrhosis[cirrhosis.isnull().any(axis=1)].Status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status\n",
       "C     0.366379\n",
       "D     0.310559\n",
       "CL    0.280000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cirrhosis[\n",
    "    cirrhosis.isnull().any(axis=1)\n",
    "].Status.value_counts() / cirrhosis.Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encoding\n",
    "encoder = ce.OrdinalEncoder(handle_missing=\"return_nan\")\n",
    "encoded_df = encoder.fit_transform(cirrhosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Status</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>261.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1718.0</td>\n",
       "      <td>137.95</td>\n",
       "      <td>172.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>302.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7394.8</td>\n",
       "      <td>113.52</td>\n",
       "      <td>88.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25594</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>176.0</td>\n",
       "      <td>3.48</td>\n",
       "      <td>210.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>96.10</td>\n",
       "      <td>55.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>244.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6121.8</td>\n",
       "      <td>60.63</td>\n",
       "      <td>92.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1504</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>279.0</td>\n",
       "      <td>3.53</td>\n",
       "      <td>143.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>113.15</td>\n",
       "      <td>72.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>414</td>\n",
       "      <td>681</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>415</td>\n",
       "      <td>1103</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>416</td>\n",
       "      <td>1055</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>417</td>\n",
       "      <td>691</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>418</td>\n",
       "      <td>976</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19358</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  N_Days  Status  Drug    Age  Sex  Ascites  Hepatomegaly  Spiders  \\\n",
       "0      1     400     1.0   1.0  21464  1.0      1.0           1.0      1.0   \n",
       "1      2    4500     2.0   1.0  20617  1.0      2.0           1.0      1.0   \n",
       "2      3    1012     1.0   1.0  25594  2.0      2.0           2.0      2.0   \n",
       "3      4    1925     1.0   1.0  19994  1.0      2.0           1.0      1.0   \n",
       "4      5    1504     3.0   2.0  13918  1.0      2.0           1.0      1.0   \n",
       "..   ...     ...     ...   ...    ...  ...      ...           ...      ...   \n",
       "413  414     681     1.0   NaN  24472  1.0      NaN           NaN      NaN   \n",
       "414  415    1103     2.0   NaN  14245  1.0      NaN           NaN      NaN   \n",
       "415  416    1055     2.0   NaN  20819  1.0      NaN           NaN      NaN   \n",
       "416  417     691     2.0   NaN  21185  1.0      NaN           NaN      NaN   \n",
       "417  418     976     2.0   NaN  19358  1.0      NaN           NaN      NaN   \n",
       "\n",
       "     Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
       "0      1.0       14.5        261.0     2.60   156.0    1718.0  137.95   \n",
       "1      2.0        1.1        302.0     4.14    54.0    7394.8  113.52   \n",
       "2      3.0        1.4        176.0     3.48   210.0     516.0   96.10   \n",
       "3      3.0        1.8        244.0     2.54    64.0    6121.8   60.63   \n",
       "4      2.0        3.4        279.0     3.53   143.0     671.0  113.15   \n",
       "..     ...        ...          ...      ...     ...       ...     ...   \n",
       "413    2.0        1.2          NaN     2.96     NaN       NaN     NaN   \n",
       "414    2.0        0.9          NaN     3.83     NaN       NaN     NaN   \n",
       "415    2.0        1.6          NaN     3.42     NaN       NaN     NaN   \n",
       "416    2.0        0.8          NaN     3.75     NaN       NaN     NaN   \n",
       "417    2.0        0.7          NaN     3.29     NaN       NaN     NaN   \n",
       "\n",
       "     Tryglicerides  Platelets  Prothrombin  Stage  \n",
       "0            172.0      190.0         12.2    4.0  \n",
       "1             88.0      221.0         10.6    3.0  \n",
       "2             55.0      151.0         12.0    4.0  \n",
       "3             92.0      183.0         10.3    4.0  \n",
       "4             72.0      136.0         10.9    3.0  \n",
       "..             ...        ...          ...    ...  \n",
       "413            NaN      174.0         10.9    3.0  \n",
       "414            NaN      180.0         11.2    4.0  \n",
       "415            NaN      143.0          9.9    3.0  \n",
       "416            NaN      269.0         10.4    3.0  \n",
       "417            NaN      350.0         10.6    4.0  \n",
       "\n",
       "[418 rows x 20 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    encoded_df, test_size=0.2, stratify=cirrhosis[[\"Status\", \"Sex\"]], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240902_085448\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\n",
      "CPU Count:          8\n",
      "Memory Avail:       50.17 GB / 54.92 GB (91.3%)\n",
      "Disk Space Avail:   4426.19 GB / 5120.00 GB (86.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240902_085448/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetTorch_BAG_L2       0.575511   0.550436    f1_macro        0.717962       0.252137  11.664446                 0.300551                0.125110           5.257555            2       True          3\n",
      "1  NeuralNetTorch_BAG_L1       0.574510   0.581787    f1_macro        0.417411       0.127028   6.406891                 0.417411                0.127028           6.406891            1       True          1\n",
      "2    WeightedEnsemble_L3       0.574510   0.581787    f1_macro        0.431740       0.130067   6.529277                 0.014330                0.003039           0.122386            3       True          4\n",
      "3    WeightedEnsemble_L2       0.574510   0.581787    f1_macro        0.448348       0.130309   6.413716                 0.030937                0.003282           0.006824            2       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t33s\t = DyStack   runtime |\t3567s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3567s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240902_085448\"\n",
      "Train Data Rows:    334\n",
      "Train Data Columns: 19\n",
      "Label Column:       Status\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51104.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 16 | ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', ...]\n",
      "\t\t('int', [])   :  3 | ['ID', 'N_Days', 'Age']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 15 | ['Drug', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', ...]\n",
      "\t\t('int', [])       :  3 | ['ID', 'N_Days', 'Age']\n",
      "\t\t('int', ['bool']) :  1 | ['Sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_layers': 3, 'hidden_size': 128},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2377.62s of the 3567.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.6211\t = Validation score   (f1_macro)\n",
      "\t6.71s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3556.14s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.6211\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3553.99s of the 3553.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.5575\t = Validation score   (f1_macro)\n",
      "\t7.88s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3541.65s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.6211\t = Validation score   (f1_macro)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 28.39s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 294.2 rows/s (42 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240902_085448\")\n"
     ]
    }
   ],
   "source": [
    "baseline_res = cal_ml_efficiency(\n",
    "    train=train_df, test=test_df, label=\"Status\", eval_metric=\"f1_macro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Miss Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available imputing algorithms:\n",
      "hyperimpute\n",
      "sklearn_ice\n",
      "most_frequent\n",
      "mice\n",
      "sklearn_missforest\n",
      "miracle\n",
      "sinkhorn\n",
      "EM\n",
      "nop\n",
      "softimpute\n",
      "median\n",
      "mean\n",
      "miwae\n",
      "missforest\n",
      "gain\n",
      "ice\n"
     ]
    }
   ],
   "source": [
    "train_imputed_mf, test_imputed_mf = impute_missing_values(\n",
    "    algo=\"missforest\",\n",
    "    df_missing=encoded_df,\n",
    "    train_indices=train_df.index,\n",
    "    test_indices=test_df.index,\n",
    "    categorical_cols=categorical_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240902_085639\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\n",
      "CPU Count:          8\n",
      "Memory Avail:       50.49 GB / 54.92 GB (91.9%)\n",
      "Disk Space Avail:   4426.19 GB / 5120.00 GB (86.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240902_085639/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetTorch_BAG_L1       0.594118   0.579370    f1_macro        0.426980       0.113788   6.556816                 0.426980                0.113788           6.556816            1       True          1\n",
      "1    WeightedEnsemble_L2       0.594118   0.579370    f1_macro        0.460462       0.116979   6.563599                 0.033482                0.003191           0.006784            2       True          2\n",
      "2  NeuralNetTorch_BAG_L2       0.594118   0.599915    f1_macro        0.747641       0.256585  12.365013                 0.320662                0.142797           5.808197            2       True          3\n",
      "3    WeightedEnsemble_L3       0.594118   0.599915    f1_macro        0.767908       0.260075  12.496824                 0.020267                0.003489           0.131811            3       True          4\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t34s\t = DyStack   runtime |\t3566s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 3566s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240902_085639\"\n",
      "Train Data Rows:    334\n",
      "Train Data Columns: 19\n",
      "Label Column:       Status\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51432.13 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 19 | ['ID', 'N_Days', 'Drug', 'Age', 'Sex', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 14 | ['ID', 'N_Days', 'Age', 'Edema', 'Bilirubin', ...]\n",
      "\t\t('int', ['bool']) :  5 | ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders']\n",
      "\t0.1s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_layers': 3, 'hidden_size': 128},\n",
      "}\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3565.76s of the 3565.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.5984\t = Validation score   (f1_macro)\n",
      "\t7.11s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3554.13s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.5984\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.11s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 368.1 rows/s (42 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240902_085639\")\n"
     ]
    }
   ],
   "source": [
    "mf_res = cal_ml_efficiency(\n",
    "    train=train_imputed_mf, test=test_imputed_mf, label=\"Status\", eval_metric=\"f1_macro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available imputing algorithms:\n",
      "hyperimpute\n",
      "sklearn_ice\n",
      "most_frequent\n",
      "mice\n",
      "sklearn_missforest\n",
      "miracle\n",
      "sinkhorn\n",
      "EM\n",
      "nop\n",
      "softimpute\n",
      "median\n",
      "mean\n",
      "miwae\n",
      "missforest\n",
      "gain\n",
      "ice\n"
     ]
    }
   ],
   "source": [
    "train_imputed_gain, test_imputed_gain = impute_missing_values(\n",
    "    algo=\"gain\",\n",
    "    df_missing=encoded_df,\n",
    "    train_indices=train_df.index,\n",
    "    test_indices=test_df.index,\n",
    "    categorical_cols=categorical_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240902_085737\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\n",
      "CPU Count:          8\n",
      "Memory Avail:       50.13 GB / 54.92 GB (91.3%)\n",
      "Disk Space Avail:   4426.19 GB / 5120.00 GB (86.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240902_085737/ds_sub_fit/sub_fit_ho\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetTorch_BAG_L2       0.575511   0.601894    f1_macro        0.806345       0.264044  14.249553                 0.363046                0.135473           7.267409            2       True          3\n",
      "1  NeuralNetTorch_BAG_L1       0.556548   0.637917    f1_macro        0.443298       0.128571   6.982144                 0.443298                0.128571           6.982144            1       True          1\n",
      "2    WeightedEnsemble_L3       0.556548   0.637917    f1_macro        0.460688       0.131571   7.102684                 0.017390                0.003000           0.120540            3       True          4\n",
      "3    WeightedEnsemble_L2       0.556548   0.637917    f1_macro        0.479300       0.131874   6.988757                 0.036001                0.003304           0.006613            2       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t36s\t = DyStack   runtime |\t3564s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3564s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240902_085737\"\n",
      "Train Data Rows:    334\n",
      "Train Data Columns: 19\n",
      "Label Column:       Status\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51106.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 19 | ['ID', 'N_Days', 'Drug', 'Age', 'Sex', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 14 | ['ID', 'N_Days', 'Age', 'Edema', 'Bilirubin', ...]\n",
      "\t\t('int', ['bool']) :  5 | ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders']\n",
      "\t0.1s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_layers': 3, 'hidden_size': 128},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2375.46s of the 3564.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.6342\t = Validation score   (f1_macro)\n",
      "\t7.47s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3552.25s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.6342\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3550.04s of the 3550.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.5687\t = Validation score   (f1_macro)\n",
      "\t6.55s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3538.97s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.6342\t = Validation score   (f1_macro)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 27.81s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 360.4 rows/s (42 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240902_085737\")\n"
     ]
    }
   ],
   "source": [
    "gain_res = cal_ml_efficiency(\n",
    "    train=train_imputed_gain,\n",
    "    test=test_imputed_gain,\n",
    "    label=\"Status\",\n",
    "    eval_metric=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIRACLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available imputing algorithms:\n",
      "hyperimpute\n",
      "sklearn_ice\n",
      "most_frequent\n",
      "mice\n",
      "sklearn_missforest\n",
      "miracle\n",
      "sinkhorn\n",
      "EM\n",
      "nop\n",
      "softimpute\n",
      "median\n",
      "mean\n",
      "miwae\n",
      "missforest\n",
      "gain\n",
      "ice\n"
     ]
    }
   ],
   "source": [
    "train_imputed_miracle, test_imputed_miracle = impute_missing_values(\n",
    "    algo=\"miracle\",\n",
    "    df_missing=encoded_df,\n",
    "    train_indices=train_df.index,\n",
    "    test_indices=test_df.index,\n",
    "    categorical_cols=categorical_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240902_085852\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\n",
      "CPU Count:          8\n",
      "Memory Avail:       50.14 GB / 54.92 GB (91.3%)\n",
      "Disk Space Avail:   4426.18 GB / 5120.00 GB (86.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240902_085852/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetTorch_BAG_L1       0.575511   0.624242    f1_macro        0.467163       0.162097   6.366832                 0.467163                0.162097           6.366832            1       True          1\n",
      "1    WeightedEnsemble_L3       0.575511   0.624242    f1_macro        0.483645       0.165415   6.499299                 0.016482                0.003318           0.132466            3       True          4\n",
      "2    WeightedEnsemble_L2       0.575511   0.624242    f1_macro        0.499952       0.165264   6.373328                 0.032789                0.003167           0.006496            2       True          2\n",
      "3  NeuralNetTorch_BAG_L2       0.539049   0.550699    f1_macro        0.800861       0.321417  11.367532                 0.333698                0.159320           5.000700            2       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t33s\t = DyStack   runtime |\t3567s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3567s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240902_085852\"\n",
      "Train Data Rows:    334\n",
      "Train Data Columns: 19\n",
      "Label Column:       Status\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51065.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 19 | ['ID', 'N_Days', 'Drug', 'Age', 'Sex', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 18 | ['ID', 'N_Days', 'Drug', 'Age', 'Ascites', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['Sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_layers': 3, 'hidden_size': 128},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2377.63s of the 3567.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.6541\t = Validation score   (f1_macro)\n",
      "\t8.37s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3553.91s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.6541\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3551.78s of the 3551.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.5576\t = Validation score   (f1_macro)\n",
      "\t5.99s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3541.45s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.889, 'NeuralNetTorch_BAG_L2': 0.111}\n",
      "\t0.6562\t = Validation score   (f1_macro)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 28.72s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 133.3 rows/s (42 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240902_085852\")\n"
     ]
    }
   ],
   "source": [
    "miracle_res = cal_ml_efficiency(\n",
    "    train=train_imputed_miracle,\n",
    "    test=test_imputed_miracle,\n",
    "    label=\"Status\",\n",
    "    eval_metric=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available imputing algorithms:\n",
      "hyperimpute\n",
      "sklearn_ice\n",
      "most_frequent\n",
      "mice\n",
      "sklearn_missforest\n",
      "miracle\n",
      "sinkhorn\n",
      "EM\n",
      "nop\n",
      "softimpute\n",
      "median\n",
      "mean\n",
      "miwae\n",
      "missforest\n",
      "gain\n",
      "ice\n"
     ]
    }
   ],
   "source": [
    "train_imputed_mice, test_imputed_mice = impute_missing_values(\n",
    "    algo=\"mice\",\n",
    "    df_missing=encoded_df,\n",
    "    train_indices=train_df.index,\n",
    "    test_indices=test_df.index,\n",
    "    categorical_cols=categorical_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240902_090005\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\n",
      "CPU Count:          8\n",
      "Memory Avail:       50.42 GB / 54.92 GB (91.8%)\n",
      "Disk Space Avail:   4426.18 GB / 5120.00 GB (86.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240902_090005/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetTorch_BAG_L2       0.575511   0.553571    f1_macro        0.738170       0.245645  12.340716                 0.303065                0.125042           5.455264            2       True          3\n",
      "1  NeuralNetTorch_BAG_L1       0.557843   0.585237    f1_macro        0.435105       0.120603   6.885452                 0.435105                0.120603           6.885452            1       True          1\n",
      "2    WeightedEnsemble_L3       0.557843   0.585237    f1_macro        0.453940       0.123500   7.014955                 0.018835                0.002898           0.129504            3       True          4\n",
      "3    WeightedEnsemble_L2       0.557843   0.585237    f1_macro        0.474731       0.124023   6.892056                 0.039625                0.003420           0.006604            2       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t34s\t = DyStack   runtime |\t3566s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3566s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240902_090005\"\n",
      "Train Data Rows:    334\n",
      "Train Data Columns: 19\n",
      "Label Column:       Status\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51364.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 19 | ['ID', 'N_Days', 'Drug', 'Age', 'Sex', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 18 | ['ID', 'N_Days', 'Drug', 'Age', 'Ascites', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['Sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_layers': 3, 'hidden_size': 128},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2376.93s of the 3566.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.5872\t = Validation score   (f1_macro)\n",
      "\t7.03s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3554.78s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.5872\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3552.59s of the 3552.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.5537\t = Validation score   (f1_macro)\n",
      "\t6.23s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3541.89s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.5872\t = Validation score   (f1_macro)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 27.1s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 319.6 rows/s (42 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240902_090005\")\n"
     ]
    }
   ],
   "source": [
    "mice_res = cal_ml_efficiency(\n",
    "    train=train_imputed_mice,\n",
    "    test=test_imputed_mice,\n",
    "    label=\"Status\",\n",
    "    eval_metric=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "    \"Baseline\": baseline_res,\n",
    "    \"Miss Forest\": mf_res,\n",
    "    \"GAIN\": gain_res,\n",
    "    \"MIRACLE\": miracle_res,\n",
    "\t\"MICE\": mice_res,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Miss Forest</th>\n",
       "      <th>GAIN</th>\n",
       "      <th>MIRACLE</th>\n",
       "      <th>MICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.533873</td>\n",
       "      <td>0.668561</td>\n",
       "      <td>0.560396</td>\n",
       "      <td>0.535322</td>\n",
       "      <td>0.520645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.543917</td>\n",
       "      <td>0.636495</td>\n",
       "      <td>0.574220</td>\n",
       "      <td>0.549627</td>\n",
       "      <td>0.529425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.591838</td>\n",
       "      <td>0.659608</td>\n",
       "      <td>0.658538</td>\n",
       "      <td>0.587391</td>\n",
       "      <td>0.543325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Baseline  Miss Forest      GAIN   MIRACLE      MICE\n",
       "f1_macro           0.533873     0.668561  0.560396  0.535322  0.520645\n",
       "accuracy           0.785714     0.821429  0.821429  0.785714  0.761905\n",
       "balanced_accuracy  0.543917     0.636495  0.574220  0.549627  0.529425\n",
       "mcc                0.591838     0.659608  0.658538  0.587391  0.543325"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Tabular + Missing Completely at Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/saurabhbadole/breast-cancer-wisconsin-state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = (\n",
    "    pd.read_csv(\n",
    "        \"data/breast-cancer-wisconsin.data\",\n",
    "        delimiter=\",\",\n",
    "        header=None,\n",
    "        names=[\n",
    "            \"Sample code number\",\n",
    "            \"Clump Thickness\",\n",
    "            \"Uniformity of Cell Size\",\n",
    "            \" Uniformity of Cell Shape\",\n",
    "            \"Marginal Adhesion\",\n",
    "            \"Single Epithelial Cell Size\",\n",
    "            \"Bare Nuclei\",\n",
    "            \"Bland Chromatin\",\n",
    "            \"Normal Nucleoli\",\n",
    "            \"Mitoses\",\n",
    "            \"Class\",\n",
    "        ],\n",
    "    )\n",
    "    .drop(columns=[\"Sample code number\"])\n",
    "    .replace(\"?\", np.nan)\n",
    "    .apply(pd.to_numeric, errors=\"coerce\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "2    458\n",
       "4    241\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate some artificial missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori, df_miss = gene_missing_at_random(df_ori, 0.3, \"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mar, test_mar = train_test_split(\n",
    "    df_miss, test_size=0.3, stratify=df_miss[[\"Class\"]], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: apply standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import standardise\n",
    "\n",
    "# train_mar, scaler = standardise(df=train_mar, label=\"Class\")\n",
    "# test_mar , _       = standardise(df=test_mar, label=\"Class\", scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240902_092629\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\n",
      "CPU Count:          8\n",
      "Memory Avail:       50.50 GB / 54.92 GB (92.0%)\n",
      "Disk Space Avail:   4426.17 GB / 5120.00 GB (86.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240902_092629/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetTorch_BAG_L1       0.919591   0.966941    f1_macro        0.412128       0.110463   6.490331                 0.412128                0.110463           6.490331            1       True          1\n",
      "1    WeightedEnsemble_L3       0.919591   0.966941    f1_macro        0.434429       0.113823   6.621308                 0.022301                0.003360           0.130976            3       True          4\n",
      "2    WeightedEnsemble_L2       0.919591   0.966941    f1_macro        0.447956       0.113843   6.497191                 0.035827                0.003381           0.006860            2       True          2\n",
      "3  NeuralNetTorch_BAG_L2       0.898186   0.962088    f1_macro        0.765867       0.232980  13.218061                 0.353739                0.122517           6.727730            2       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t34s\t = DyStack   runtime |\t3566s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3566s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240902_092629\"\n",
      "Train Data Rows:    489\n",
      "Train Data Columns: 9\n",
      "Label Column:       Class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 4, class 0 = 2\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (4) vs negative (2) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51448.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['Clump Thickness', 'Uniformity of Cell Size', ' Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['Clump Thickness', 'Uniformity of Cell Size', ' Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_layers': 3, 'hidden_size': 128},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2376.45s of the 3565.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.9573\t = Validation score   (f1_macro)\n",
      "\t8.31s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3552.48s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.9573\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3550.3s of the 3550.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.9572\t = Validation score   (f1_macro)\n",
      "\t6.99s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3538.44s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.9573\t = Validation score   (f1_macro)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 29.8s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 529.8 rows/s (62 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240902_092629\")\n"
     ]
    }
   ],
   "source": [
    "mcar_base_res = cal_ml_efficiency(\n",
    "    train=train_mar,\n",
    "    test=test_mar,\n",
    "    label=\"Class\",\n",
    "    eval_metric=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Miss Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick your imputer from the available algorithms:  ['hyperimpute', 'sklearn_ice', 'most_frequent', 'mice', 'sklearn_missforest', 'miracle', 'sinkhorn', 'EM', 'nop', 'softimpute', 'median', 'mean', 'miwae', 'missforest', 'gain', 'ice']\n"
     ]
    }
   ],
   "source": [
    "train_imputed_mf, test_imputed_mf = impute_missing_values(\n",
    "    algo=\"missforest\",\n",
    "    df_missing=df_miss,\n",
    "    train_indices=train_mar.index,\n",
    "    test_indices=test_mar.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240902_084423\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\n",
      "CPU Count:          8\n",
      "Memory Avail:       50.11 GB / 54.92 GB (91.2%)\n",
      "Disk Space Avail:   4426.20 GB / 5120.00 GB (86.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240902_084423/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetTorch_BAG_L2       0.960714   0.979560    f1_macro        0.690173       0.223869  12.264985                 0.280877                0.106777           5.619797            2       True          3\n",
      "1  NeuralNetTorch_BAG_L1       0.941676   0.982254    f1_macro        0.409296       0.117092   6.645188                 0.409296                0.117092           6.645188            1       True          1\n",
      "2    WeightedEnsemble_L3       0.941676   0.982254    f1_macro        0.431624       0.120204   6.773978                 0.022329                0.003113           0.128790            3       True          4\n",
      "3    WeightedEnsemble_L2       0.941676   0.982254    f1_macro        0.442111       0.120311   6.652362                 0.032815                0.003219           0.007174            2       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t34s\t = DyStack   runtime |\t3566s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3566s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240902_084423\"\n",
      "Train Data Rows:    489\n",
      "Train Data Columns: 9\n",
      "Label Column:       Class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 4, class 0 = 2\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (4) vs negative (2) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51130.40 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['Clump Thickness', 'Uniformity of Cell Size', ' Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['Clump Thickness', 'Uniformity of Cell Size', ' Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_layers': 3, 'hidden_size': 128},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2376.92s of the 3566.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.9775\t = Validation score   (f1_macro)\n",
      "\t6.05s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3555.71s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.9775\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3553.54s of the 3553.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.9753\t = Validation score   (f1_macro)\n",
      "\t5.57s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3543.45s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.9775\t = Validation score   (f1_macro)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 25.47s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 389.8 rows/s (62 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240902_084423\")\n"
     ]
    }
   ],
   "source": [
    "mf_res = cal_ml_efficiency(\n",
    "    train=train_imputed_mf,  # .clip(lower=1, upper=10).round()\n",
    "    test=test_imputed_mf,  # .clip(lower=1, upper=10).round()\n",
    "    label=\"Class\",\n",
    "    eval_metric=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available imputing algorithms:\n",
      "hyperimpute\n",
      "sklearn_ice\n",
      "most_frequent\n",
      "mice\n",
      "sklearn_missforest\n",
      "miracle\n",
      "sinkhorn\n",
      "EM\n",
      "nop\n",
      "softimpute\n",
      "median\n",
      "mean\n",
      "miwae\n",
      "missforest\n",
      "gain\n",
      "ice\n"
     ]
    }
   ],
   "source": [
    "train_imputed_gain, test_imputed_gain = impute_missing_values(\n",
    "    algo=\"gain\",\n",
    "    df_missing=df_miss,\n",
    "    train_indices=train_mar.index,\n",
    "    test_indices=test_mar.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240902_084530\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\n",
      "CPU Count:          8\n",
      "Memory Avail:       50.47 GB / 54.92 GB (91.9%)\n",
      "Disk Space Avail:   4426.20 GB / 5120.00 GB (86.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240902_084530/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetTorch_BAG_L1       0.941676   0.979624    f1_macro        0.453835       0.165877   6.259172                 0.453835                0.165877           6.259172            1       True          1\n",
      "1    WeightedEnsemble_L3       0.941676   0.979624    f1_macro        0.472062       0.173218   6.385157                 0.018227                0.007341           0.125985            3       True          4\n",
      "2    WeightedEnsemble_L2       0.941676   0.979624    f1_macro        0.485315       0.168806   6.266198                 0.031480                0.002929           0.007026            2       True          2\n",
      "3  NeuralNetTorch_BAG_L2       0.941676   0.977041    f1_macro        0.755788       0.278854  11.713744                 0.301953                0.112978           5.454572            2       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t34s\t = DyStack   runtime |\t3566s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3566s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240902_084530\"\n",
      "Train Data Rows:    489\n",
      "Train Data Columns: 9\n",
      "Label Column:       Class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 4.0, class 0 = 2.0\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (4.0) vs negative (2.0) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51430.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['Clump Thickness', 'Uniformity of Cell Size', ' Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['Clump Thickness', 'Uniformity of Cell Size', ' Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_layers': 3, 'hidden_size': 128},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2376.77s of the 3566.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.9775\t = Validation score   (f1_macro)\n",
      "\t7.04s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3554.56s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.9775\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3552.39s of the 3552.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.9729\t = Validation score   (f1_macro)\n",
      "\t6.24s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3541.5s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.9775\t = Validation score   (f1_macro)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 27.13s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 476.2 rows/s (62 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240902_084530\")\n"
     ]
    }
   ],
   "source": [
    "gain_res = cal_ml_efficiency(\n",
    "    train=train_imputed_gain,  # .clip(lower=1, upper=10).round()\n",
    "    test=test_imputed_gain,  # .clip(lower=1, upper=10).round()\n",
    "    label=\"Class\",\n",
    "    eval_metric=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIRACLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available imputing algorithms:\n",
      "hyperimpute\n",
      "sklearn_ice\n",
      "most_frequent\n",
      "mice\n",
      "sklearn_missforest\n",
      "miracle\n",
      "sinkhorn\n",
      "EM\n",
      "nop\n",
      "softimpute\n",
      "median\n",
      "mean\n",
      "miwae\n",
      "missforest\n",
      "gain\n",
      "ice\n"
     ]
    }
   ],
   "source": [
    "train_imputed_miracle, test_imputed_miracle = impute_missing_values(\n",
    "    algo=\"miracle\",\n",
    "    df_missing=df_miss,\n",
    "    train_indices=train_mar.index,\n",
    "    test_indices=test_mar.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240902_084639\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\n",
      "CPU Count:          8\n",
      "Memory Avail:       50.49 GB / 54.92 GB (91.9%)\n",
      "Disk Space Avail:   4426.19 GB / 5120.00 GB (86.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240902_084639/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetTorch_BAG_L1       0.959795   0.969437    f1_macro        0.357414       0.043897   6.418519                 0.357414                0.043897           6.418519            1       True          1\n",
      "1    WeightedEnsemble_L3       0.959795   0.969437    f1_macro        0.375324       0.047020   6.545099                 0.017910                0.003123           0.126581            3       True          4\n",
      "2    WeightedEnsemble_L2       0.959795   0.969437    f1_macro        0.392287       0.047051   6.425032                 0.034873                0.003154           0.006514            2       True          2\n",
      "3  NeuralNetTorch_BAG_L2       0.959795   0.967143    f1_macro        0.587209       0.108114  13.391525                 0.229795                0.064217           6.973006            2       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t35s\t = DyStack   runtime |\t3565s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3565s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240902_084639\"\n",
      "Train Data Rows:    489\n",
      "Train Data Columns: 9\n",
      "Label Column:       Class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 4.0, class 0 = 2.0\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (4.0) vs negative (2.0) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51058.90 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['Clump Thickness', 'Uniformity of Cell Size', ' Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['Clump Thickness', 'Uniformity of Cell Size', ' Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_layers': 3, 'hidden_size': 128},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2376.2s of the 3565.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.9616\t = Validation score   (f1_macro)\n",
      "\t6.46s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3554.23s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.9616\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3552.05s of the 3552.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.9662\t = Validation score   (f1_macro)\n",
      "\t5.88s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3541.63s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L2': 1.0}\n",
      "\t0.9662\t = Validation score   (f1_macro)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 26.21s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 576.8 rows/s (62 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240902_084639\")\n"
     ]
    }
   ],
   "source": [
    "miracle_res = cal_ml_efficiency(\n",
    "    train=train_imputed_miracle,  # .clip(lower=1, upper=10).round()\n",
    "    test=test_imputed_miracle,  # .clip(lower=1, upper=10).round()\n",
    "    label=\"Class\",\n",
    "    eval_metric=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available imputing algorithms:\n",
      "hyperimpute\n",
      "sklearn_ice\n",
      "most_frequent\n",
      "mice\n",
      "sklearn_missforest\n",
      "miracle\n",
      "sinkhorn\n",
      "EM\n",
      "nop\n",
      "softimpute\n",
      "median\n",
      "mean\n",
      "miwae\n",
      "missforest\n",
      "gain\n",
      "ice\n"
     ]
    }
   ],
   "source": [
    "train_imputed_mice, test_imputed_mice = impute_missing_values(\n",
    "    algo=\"mice\",\n",
    "    df_missing=df_miss,\n",
    "    train_indices=train_mar.index,\n",
    "    test_indices=test_mar.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240902_085044\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\n",
      "CPU Count:          8\n",
      "Memory Avail:       48.08 GB / 54.92 GB (87.5%)\n",
      "Disk Space Avail:   4426.19 GB / 5120.00 GB (86.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240902_085044/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  NeuralNetTorch_BAG_L1            1.0   0.984766    f1_macro        0.422030       0.101491   5.604023                 0.422030                0.101491           5.604023            1       True          1\n",
      "1    WeightedEnsemble_L3            1.0   0.984766    f1_macro        0.437868       0.104957   5.729085                 0.015837                0.003465           0.125062            3       True          4\n",
      "2    WeightedEnsemble_L2            1.0   0.984766    f1_macro        0.459342       0.104575   5.612148                 0.037312                0.003084           0.008126            2       True          2\n",
      "3  NeuralNetTorch_BAG_L2            1.0   0.979811    f1_macro        0.701763       0.223688  10.763893                 0.279733                0.122197           5.159870            2       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t35s\t = DyStack   runtime |\t3565s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3565s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240902_085044\"\n",
      "Train Data Rows:    489\n",
      "Train Data Columns: 9\n",
      "Label Column:       Class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 4.0, class 0 = 2.0\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (4.0) vs negative (2.0) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51110.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['Clump Thickness', 'Uniformity of Cell Size', ' Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['Clump Thickness', 'Uniformity of Cell Size', ' Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {'num_layers': 3, 'hidden_size': 128},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2375.93s of the 3564.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.991\t = Validation score   (f1_macro)\n",
      "\t5.5s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3554.8s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.991\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3552.64s of the 3552.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.9887\t = Validation score   (f1_macro)\n",
      "\t6.74s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 3541.28s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 1.0}\n",
      "\t0.991\t = Validation score   (f1_macro)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 26.13s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 540.1 rows/s (62 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240902_085044\")\n"
     ]
    }
   ],
   "source": [
    "mice_res = cal_ml_efficiency(\n",
    "    train=train_imputed_mice,  # .clip(lower=1, upper=10).round()\n",
    "    test=test_imputed_mice,  # .clip(lower=1, upper=10).round()\n",
    "    label=\"Class\",\n",
    "    eval_metric=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "    \"Baseline\": mar_base_res,\n",
    "    \"Miss Forest\": mf_res,\n",
    "    \"GAIN\": gain_res,\n",
    "    \"MIRACLE\": miracle_res,\n",
    "\t\"MICE\": mice_res,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Miss Forest</th>\n",
       "      <th>GAIN</th>\n",
       "      <th>MIRACLE</th>\n",
       "      <th>MICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.926507</td>\n",
       "      <td>0.952904</td>\n",
       "      <td>0.952904</td>\n",
       "      <td>0.925524</td>\n",
       "      <td>0.963135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.957428</td>\n",
       "      <td>0.957428</td>\n",
       "      <td>0.922705</td>\n",
       "      <td>0.964674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.853217</td>\n",
       "      <td>0.906276</td>\n",
       "      <td>0.906276</td>\n",
       "      <td>0.851257</td>\n",
       "      <td>0.926323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.981985</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>0.992854</td>\n",
       "      <td>0.980676</td>\n",
       "      <td>0.995370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.951724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.945205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Baseline  Miss Forest      GAIN   MIRACLE      MICE\n",
       "f1_macro           0.926507     0.952904  0.952904  0.925524  0.963135\n",
       "accuracy           0.933333     0.957143  0.957143  0.933333  0.966667\n",
       "balanced_accuracy  0.929348     0.957428  0.957428  0.922705  0.964674\n",
       "mcc                0.853217     0.906276  0.906276  0.851257  0.926323\n",
       "roc_auc            0.981985     0.991445  0.992854  0.980676  0.995370\n",
       "f1                 0.904110     0.938776  0.938776  0.901408  0.951724\n",
       "precision          0.891892     0.920000  0.920000  0.914286  0.945205\n",
       "recall             0.916667     0.958333  0.958333  0.888889  0.958333"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.2915080527086384, 'rmse': 0.9155401481153775}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_metrics(\n",
    "    original=df_ori,\n",
    "    imputed=pd.concat([train_imputed_mf, test_imputed_mf])\n",
    "    .sort_index()\n",
    "    .clip(lower=1, upper=10)\n",
    "    .round(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.31961932650073205, 'rmse': 0.9522263347961742}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_metrics(\n",
    "    original=df_ori,\n",
    "    imputed=pd.concat([train_imputed_gain, test_imputed_gain])\n",
    "    .sort_index()\n",
    "    .clip(lower=1, upper=10)\n",
    "    .round(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.590190336749634, 'rmse': 1.889982840951801}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_metrics(\n",
    "    original=df_ori,\n",
    "    imputed=pd.concat([train_imputed_miracle, test_imputed_miracle])\n",
    "    .sort_index()\n",
    "    .clip(lower=1, upper=10)\n",
    "    .round(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.4292825768667643, 'rmse': 1.1909861558498744}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_metrics(\n",
    "    original=df_ori,\n",
    "    imputed=pd.concat([train_imputed_mice, test_imputed_mice])\n",
    "    .sort_index()\n",
    "    .clip(lower=1, upper=10)\n",
    "    .round(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.590190336749634, 'rmse': 1.889982840951801}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cal_metrics(\n",
    "\toriginal=df_ori,\n",
    "\timputed=pd.concat([train_imputed_miracle, test_imputed_miracle]).sort_index().clip(lower=1, upper=10).round(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
